{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9ef89db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from data_loader import load_fold, get_conditions_by_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "213b0da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"results/bertweet-base_eng_cognitive_attention_20250421_023107/fold_1/final_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f6e9e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original class distribution in training set (users):\n",
      "  CONTROL: 1362 users\n",
      "  ADHD: 498 users\n",
      "  ASD: 136 users\n",
      "\n",
      "Full balancing: Reducing all classes to match smallest class ASD (136 users)\n",
      "\n",
      "Final class distribution in training set (users):\n",
      "  ADHD: 136 users\n",
      "  ASD: 136 users\n",
      "  CONTROL: 136 users\n",
      "Loading train data...\n",
      "Loading test data...\n",
      "Sample tweet: \" Im very detailed in all aspect of my life the fact that people notice HTTPURL \"\n",
      "ADHD\n"
     ]
    }
   ],
   "source": [
    "fold = 1\n",
    "group = \"cognitive_attention\"\n",
    "language = \"eng\"\n",
    "dataset_dict = load_fold(fold, language=language, group=group, balance_level=\"full\")\n",
    "sample = dataset_dict[\"test\"][5] \n",
    "text = sample[\"tweet\"]\n",
    "print(\"Sample tweet:\", text)\n",
    "print(sample[\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdb7a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers_interpret import SequenceClassificationExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65f9266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_explainer = SequenceClassificationExplainer(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc32aa47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 0.0),\n",
       " ('\"', 0.07382133603096008),\n",
       " ('My', 0.022843321785330772),\n",
       " ('little', 0.4132058024406433),\n",
       " ('Melody', 0.6295004487037659),\n",
       " ('is', -0.11366540193557739),\n",
       " ('12', -0.1502915620803833),\n",
       " ('today', 0.19136029481887817),\n",
       " ('!', 0.29310551285743713),\n",
       " ('<unk>', 0.33143147826194763),\n",
       " (':two_hearts:', 0.37707796692848206),\n",
       " ('\"', -0.13018174469470978),\n",
       " ('</s>', 0.0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_explainer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fe2bcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_tweets = {\"ADHD\": [], \"ASD\": [], \"CONTROL\": []}\n",
    "for sample in dataset_dict[\"test\"]:\n",
    "    tweet = sample[\"tweet\"]\n",
    "    label = sample[\"class\"]\n",
    "    grouped_tweets[label].append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244c0626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_influential_words(tweets):\n",
    "    influential_words = []\n",
    "    counter = 0\n",
    "    for text in tweets:\n",
    "        counter += 1\n",
    "        attributions = cls_explainer(text)\n",
    "        sorted_attributions = sorted(attributions, key=lambda x: abs(x[1]), reverse=True)\n",
    "        top_words = [(word, score) for word, score in sorted_attributions[:15]]\n",
    "        influential_words.append({\"tweet\": text, \"top_words\": top_words})\n",
    "        if (counter % 10000 == 0):\n",
    "            print(counter)\n",
    "    return influential_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d584ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for group, tweets in grouped_tweets.items():\n",
    "    print(f\"Processing group: {group}\")\n",
    "    results[group] = compute_influential_words(tweets[1:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd75375",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group, data in results.items():\n",
    "    print(f\"\\nGroup: {group}\")\n",
    "    for entry in data:\n",
    "        print(f\"Tweet: {entry['tweet']}\")\n",
    "        print(\"Top 15 Influential Words:\")\n",
    "        for word, score in entry[\"top_words\"]:\n",
    "            print(f\"  {word}: {score}\")\n",
    "        print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mentalIllness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
